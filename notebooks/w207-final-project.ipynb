{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W207 Final Project - BaseLine\n",
    "\n",
    "## Submission by Sirisha Bhupathi and Abhi Sharma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is for the Kaggle competition listed here: https://www.kaggle.com/c/facial-keypoints-detection\n",
    "\n",
    "## Objective\n",
    "\n",
    "The objective of this project is to predict keypoint positions on face images.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The image sizes are 96 x 96 pixels and the key points are represented as location co-ordinates for each image. \n",
    "Location co-ordinates can have 2 values - one for x and one for y. \n",
    "There are a total of 30 location co-ordinates per image, 15 each for the x and y axis.\n",
    "Out of the 30 co-ordinates in the test dataset for a single image, some co-ordinates are present and others need to be predicted. \n",
    "The number and type of co-ordinates that need to be predicted vary per test example.\n",
    "\n",
    "\n",
    "## Methodology\n",
    "\n",
    "This notebook introduces basic EDA and feature preparation for the test and training data.\n",
    "We were able to successfully extract the images and plot the keypoints on top of them.\n",
    "\n",
    "For now, we have just used the image pixel values (normalized by 255) as the features in the model.\n",
    "We ran a vanilla neural network with 1 hidden layer for our baseline. We used standard activation functions for training (relu and sigmoid).\n",
    "\n",
    "So far, we have a public score of 3.96505 on Kaggle with the above methodology.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "We intend to augment the image data set via a combination of image augmentation techniques - blurring / zooming, translation, rotation etc.\n",
    "We will append this to the list of features for the dataset in our next iteration of training.\n",
    "\n",
    "We will also use Convolutional Neural Nets and possibly certain pre-trained image neural network architectures for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "IMG_DIM = 96\n",
    "PIX_MAX = 255\n",
    "IMAGE = \"Image\"\n",
    "columns = ['left_eye_center_x', 'left_eye_center_y', 'right_eye_center_x',\n",
    "       'right_eye_center_y', 'left_eye_inner_corner_x',\n",
    "       'left_eye_inner_corner_y', 'left_eye_outer_corner_x',\n",
    "       'left_eye_outer_corner_y', 'right_eye_inner_corner_x',\n",
    "       'right_eye_inner_corner_y', 'right_eye_outer_corner_x',\n",
    "       'right_eye_outer_corner_y', 'left_eyebrow_inner_end_x',\n",
    "       'left_eyebrow_inner_end_y', 'left_eyebrow_outer_end_x',\n",
    "       'left_eyebrow_outer_end_y', 'right_eyebrow_inner_end_x',\n",
    "       'right_eyebrow_inner_end_y', 'right_eyebrow_outer_end_x',\n",
    "       'right_eyebrow_outer_end_y', 'nose_tip_x', 'nose_tip_y',\n",
    "       'mouth_left_corner_x', 'mouth_left_corner_y', 'mouth_right_corner_x',\n",
    "       'mouth_right_corner_y', 'mouth_center_top_lip_x',\n",
    "       'mouth_center_top_lip_y', 'mouth_center_bottom_lip_x',\n",
    "       'mouth_center_bottom_lip_y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "folder_prefix = \"..\"\n",
    "if cwd == '/project/notebooks':\n",
    "    folder_prefix = \"/project/kaggle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(folder_prefix + '/input/facial-keypoints-detection/training.zip')\n",
    "test = pd.read_csv(folder_prefix + '/input/facial-keypoints-detection/test.zip')\n",
    "idlookup = pd.read_csv(folder_prefix + '/input/facial-keypoints-detection/IdLookupTable.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train shape:',train.shape)\n",
    "print('Test shape:',test.shape)\n",
    "print(test.head())\n",
    "train.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for missing values\n",
    "\n",
    "train.isnull().any().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with mean of the column\n",
    "\n",
    "for col in columns:\n",
    "    mean = np.mean(train[col])\n",
    "    train[col] = train[col].fillna(mean)\n",
    "train.isnull().any().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split image column and label columns\n",
    "\n",
    "train_images = train[[IMAGE]]\n",
    "train_labels = train.drop(IMAGE, axis=1)\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train image pixels from string to 1 pixel per column and convert each pixel from string to float\n",
    "train_images = train_images[IMAGE].str.split(' ', expand=True)\n",
    "train_images = train_images.astype(float)\n",
    "\n",
    "train_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split test image pixels from string to 1 pixel per column and convert each pixel from string to float\n",
    "test_images = test.copy()\n",
    "test_images = test_images.set_index(\"ImageId\")\n",
    "test_images = test_images[IMAGE].str.split(' ', expand=True)\n",
    "test_images = test_images.astype(float)\n",
    "\n",
    "test_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of flat representation, have a dataframe with 2d representation of each row's image as well\n",
    "train_images_2d = train_images.values.reshape(-1, IMG_DIM, IMG_DIM, 1)\n",
    "test_images_2d = test_images.values.reshape(-1, IMG_DIM, IMG_DIM, 1)\n",
    "\n",
    "print(train_images_2d.shape)\n",
    "print(test_images_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot images and keypoints\n",
    "\n",
    "# Can try different images\n",
    "image_no = 60 \n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(np.array(train_images.iloc[image_no]).reshape(IMG_DIM, IMG_DIM),cmap='gray')\n",
    "for i in range(0, 30, 2):\n",
    "    plt.scatter(train_labels.iloc[image_no][i],train_labels.iloc[image_no][i+1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize train and test data\n",
    "\n",
    "train_images = train_images/PIX_MAX\n",
    "train_labels = train_labels/IMG_DIM\n",
    "test_images = test_images/PIX_MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_examples = train_images.shape[0]\n",
    "num_train_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras import optimizers\n",
    "from keras.layers import Conv2D,Dropout,Dense,Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, Convolution2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout, Conv2D,MaxPool2D, ZeroPadding2D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, (3,3), padding='same', use_bias=False, input_shape=(96,96,1)))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Convolution2D(32, (3,3), padding='same', use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, (3,3), padding='same', use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Convolution2D(64, (3,3), padding='same', use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(96, (3,3), padding='same', use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Convolution2D(96, (3,3), padding='same', use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(128, (3,3),padding='same', use_bias=False))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Convolution2D(128, (3,3),padding='same', use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(256, (3,3),padding='same',use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Convolution2D(256, (3,3),padding='same',use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(512, (3,3), padding='same', use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Convolution2D(512, (3,3), padding='same', use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(30))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mse','mae'])\n",
    "\n",
    "history = model.fit(train_images_2d, train_labels, epochs = 50,batch_size = numTrainExamples,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for test\n",
    "pred = model.predict(test_images_2d)\n",
    "print(np.min(pred))\n",
    "print(np.max(pred))\n",
    "print(np.min(model.predict(train_images_2d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look up table\n",
    "print(idlookup.head(2))\n",
    "idlookup = idlookup.drop('Location',axis=1)\n",
    "print(idlookup.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = train_labels.columns\n",
    "predictions = pd.DataFrame(pred, columns = feature_names)\n",
    "predictions = predictions * IMG_DIM\n",
    "\n",
    "predictions.head()\n",
    "predictions.stack().reset_index()\n",
    "predictions = predictions.stack().reset_index()\n",
    "predictions.columns = ['index','FeatureName','Location']\n",
    "\n",
    "imageids = test['ImageId']\n",
    "imageids = imageids.reset_index()\n",
    "\n",
    "predictions = predictions.merge(imageids, left_on='index', right_on='index')\n",
    "predictions = predictions.drop('index',axis=1)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = idlookup.merge(predictions, left_on=['FeatureName','ImageId'], right_on=['FeatureName','ImageId'])\n",
    "submission = submission[['RowId','Location']]\n",
    "submission = submission.set_index('RowId')\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
