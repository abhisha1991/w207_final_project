{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W207 Final Project\n",
    "\n",
    "## Submission by Sirisha Bhupathi and Abhi Sharma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is for the Kaggle competition listed here: https://www.kaggle.com/c/facial-keypoints-detection\n",
    "\n",
    "## Objective\n",
    "\n",
    "The objective of this project is to predict keypoint positions on face images.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The image sizes are 96 x 96 pixels and the key points are represented as location co-ordinates for each image. \n",
    "Location co-ordinates can have 2 values - one for x and one for y. \n",
    "There are a total of 30 location co-ordinates per image, 15 each for the x and y axis.\n",
    "Out of the 30 co-ordinates in the test dataset for a single image, some co-ordinates are present and others need to be predicted. \n",
    "The number and type of co-ordinates that need to be predicted vary per test example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from random import seed\n",
    "from random import randint\n",
    "import time\n",
    "import math\n",
    "\n",
    "# import keras, tf and image depdencies\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "from PIL import Image, ImageDraw, ImageOps, ImageEnhance\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We verify if the GPU is working and available with the following commands\n",
    "# Adapted from here: https://www.tensorflow.org/guide/gpu\n",
    "\n",
    "tf_config = tf.compat.v1.ConfigProto(allow_soft_placement=False)\n",
    "tf_config.gpu_options.allow_growth = True\n",
    "s = tf.compat.v1.Session(config=tf_config)\n",
    "tf.compat.v1.keras.backend.set_session(s)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(gpus))\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Create some tensors\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(c)\n",
    "\n",
    "\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "IMG_DIM = 96\n",
    "PIX_MAX = 255\n",
    "IMAGE = 'Image'\n",
    "COLUMNS = ['left_eye_center_x', 'left_eye_center_y', 'right_eye_center_x',\n",
    "       'right_eye_center_y', 'left_eye_inner_corner_x',\n",
    "       'left_eye_inner_corner_y', 'left_eye_outer_corner_x',\n",
    "       'left_eye_outer_corner_y', 'right_eye_inner_corner_x',\n",
    "       'right_eye_inner_corner_y', 'right_eye_outer_corner_x',\n",
    "       'right_eye_outer_corner_y', 'left_eyebrow_inner_end_x',\n",
    "       'left_eyebrow_inner_end_y', 'left_eyebrow_outer_end_x',\n",
    "       'left_eyebrow_outer_end_y', 'right_eyebrow_inner_end_x',\n",
    "       'right_eyebrow_inner_end_y', 'right_eyebrow_outer_end_x',\n",
    "       'right_eyebrow_outer_end_y', 'nose_tip_x', 'nose_tip_y',\n",
    "       'mouth_left_corner_x', 'mouth_left_corner_y', 'mouth_right_corner_x',\n",
    "       'mouth_right_corner_y', 'mouth_center_top_lip_x',\n",
    "       'mouth_center_top_lip_y', 'mouth_center_bottom_lip_x',\n",
    "       'mouth_center_bottom_lip_y']\n",
    "\n",
    "CWD = '/project/notebooks'\n",
    "AUGMENTATIONS = [\"90R\", \"90L\", \"180H\", \"180V\", \"NoiseGaussian\", \"NoiseSaltPepper\", \"NoisePoisson\", \"NoiseSpeckle\", \"IncreaseBright\", \"IncreaseDark\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_prefix = '..'\n",
    "if os.getcwd() == CWD:\n",
    "    folder_prefix = '/project/kaggle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(folder_prefix + '/input/facial-keypoints-detection/training.zip')\n",
    "test = pd.read_csv(folder_prefix + '/input/facial-keypoints-detection/test.zip')\n",
    "idlookup = pd.read_csv(folder_prefix + '/input/facial-keypoints-detection/IdLookupTable.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train shape:',train.shape)\n",
    "print('Test shape:',test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "def check_missing_vals(data):\n",
    "    return data.isnull().any().value_counts()\n",
    "    \n",
    "def fill_missing_with_col_mean(data):\n",
    "    for col in COLUMNS:\n",
    "        mean = np.mean(data[col])\n",
    "        data[col] = data[col].fillna(mean)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_missing_vals(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_missing_vals(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = fill_missing_with_col_mean(train)\n",
    "check_missing_vals(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split image column and label columns\n",
    "\n",
    "train_images = train[[IMAGE]]\n",
    "train_labels = train.drop(IMAGE, axis=1)\n",
    "\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train image pixels from string to 1 pixel per column and convert each pixel from string to float\n",
    "\n",
    "train_images = train_images[IMAGE].str.split(' ', expand=True)\n",
    "train_images = train_images.astype(float)\n",
    "\n",
    "train_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split test image pixels from string to 1 pixel per column and convert each pixel from string to float\n",
    "\n",
    "test_images = test.copy()\n",
    "test_images = test_images.set_index('ImageId')\n",
    "test_images = test_images[IMAGE].str.split(' ', expand=True)\n",
    "test_images = test_images.astype(float)\n",
    "\n",
    "test_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_examples = train_images.shape[0]\n",
    "num_train_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to reshape image(s) to 2d\n",
    "# Note that a dataframe is converted into a numpy array as a result of this transform\n",
    "# Thus it is the user's responsibility to convert the array back to a dataframe if need be\n",
    "\n",
    "def img_reshape_2d(data, width=IMG_DIM, height=IMG_DIM):\n",
    "    data_2d = data.values.reshape(width, height)\n",
    "    # returns data of shape (width, height)\n",
    "    return data_2d\n",
    "\n",
    "def multiple_img_reshape_2d(data, width=IMG_DIM, height=IMG_DIM):\n",
    "    data_2d = data.values.reshape(-1, width, height, 1)\n",
    "    # returns data of shape (rows, width, height, color channels)\n",
    "    return data_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot images and keypoints function\n",
    "# if img_num is a valid value, we display that image only\n",
    "\n",
    "def plot_images(train_images, train_labels, start_index=0, end_offset=1000, img_num=-1):\n",
    "    rows = 4\n",
    "    cols = 4\n",
    "    multiplier = 10\n",
    "    dot_size = 100\n",
    "    \n",
    "    if img_num != -1:\n",
    "        dot_size = 50\n",
    "        multiplier = 5\n",
    "        rows = 1\n",
    "        cols = 1\n",
    "        \n",
    "    fig = plt.figure(figsize=(rows * multiplier, cols * multiplier), constrained_layout = False)\n",
    "    for i in range(1, cols * rows + 1):\n",
    "        ax = fig.add_subplot(rows, cols, i)\n",
    "        if img_num != -1:\n",
    "            image_no = img_num\n",
    "        else:\n",
    "            image_no = randint(start_index, start_index+end_offset)\n",
    "        img = np.array(train_images.iloc[image_no]).reshape(IMG_DIM, IMG_DIM)\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        for j in range(0, 30, 2):\n",
    "            ax.scatter(train_labels.iloc[image_no][j], train_labels.iloc[image_no][j+1], s=dot_size)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_image_with_label_optional(img, labels=pd.DataFrame()):\n",
    "    fig = plt.figure(figsize=(5, 5), constrained_layout = False)\n",
    "    # reshapes array in case it is given as flat representation, ie, 9216 pixels = 96 x 96 image\n",
    "    img = np.array(img).reshape(IMG_DIM, IMG_DIM)\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    if labels.empty == False:\n",
    "        for j in range(0, 30, 2):\n",
    "            ax.scatter(labels[j], labels[j+1], s=50)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display single image giving index as input\n",
    "plot_images(train_images, train_labels, img_num=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display another image directly giving image and label as input\n",
    "plot_image_with_label_optional(train_images.iloc[155], train_labels.iloc[155]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display same image without any labels\n",
    "plot_image_with_label_optional(train_images.iloc[155]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display many images\n",
    "plot_images(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation function to generate more images\n",
    "\n",
    "def augment_images(train_img_set, train_label_set, aug_list):\n",
    "    tick = time.perf_counter()\n",
    "    for aug in aug_list:\n",
    "        if aug not in AUGMENTATIONS:\n",
    "            raise NameError(\"Augmentation -- {0} -- not valid\".format(aug))\n",
    "    \n",
    "    if len(train_img_set) != len(train_label_set):\n",
    "        raise ValueError(\"Train image set size must match label set size\")\n",
    "    \n",
    "    output_imgs_flat = []\n",
    "    output_imgs_2d = []\n",
    "    output_label_set = []\n",
    "    angle = 0\n",
    "    for aug in aug_list:\n",
    "        for idx, img in train_img_set.iterrows():\n",
    "\n",
    "            labels = list(train_label_set.iloc[idx].copy())\n",
    "            input_image = img.copy()\n",
    "            if img.shape != (IMG_DIM, IMG_DIM):\n",
    "                #print(\"Converting image to 2d\")\n",
    "                input_image = img_reshape_2d(input_image)\n",
    "\n",
    "            output_image = Image.fromarray(input_image)\n",
    "            if aug == \"90R\":\n",
    "                # rotate 90 degrees to the right\n",
    "                output_image = output_image.rotate(270)\n",
    "                angle = 90\n",
    "            elif aug == \"90L\":\n",
    "                # rotate 90 degrees to the left\n",
    "                output_image = output_image.rotate(90)\n",
    "                angle = -90\n",
    "            elif aug == \"180H\":\n",
    "                # horizontal flip\n",
    "                output_image = ImageOps.mirror(output_image)\n",
    "                angle = 0\n",
    "            elif aug == \"180V\":\n",
    "                # rotate 180 degrees vertically\n",
    "                output_image = output_image.rotate(180)\n",
    "                angle = 180\n",
    "            elif aug == \"NoiseGaussian\" or aug == \"NoiseSaltPepper\" or aug == \"NoisePoisson\" or aug == \"NoiseSpeckle\":\n",
    "                output_image = add_noise_to_img(input_image, aug)\n",
    "                angle = 0\n",
    "            elif aug == \"IncreaseBright\":\n",
    "                enhancer = ImageEnhance.Brightness(output_image)\n",
    "                output_image = enhancer.enhance(1.5)\n",
    "                angle = 0\n",
    "            elif aug == \"IncreaseDark\":\n",
    "                enhancer = ImageEnhance.Brightness(output_image)\n",
    "                output_image = enhancer.enhance(0.5)\n",
    "                angle = 0\n",
    "            \n",
    "            output_image = np.array(output_image)\n",
    "            output_imgs_flat.append(output_image.reshape(IMG_DIM * IMG_DIM))\n",
    "            output_imgs_2d.append(output_image)\n",
    "            \n",
    "            labels = rotate((IMG_DIM / 2, IMG_DIM / 2), labels, angle)\n",
    "            output_label_set.append(labels)\n",
    "    \n",
    "    output_imgs_flat = np.array(output_imgs_flat)\n",
    "    output_imgs_2d = np.array(output_imgs_2d).reshape(-1, IMG_DIM, IMG_DIM, 1)\n",
    "    output_label_set = np.array(output_label_set)\n",
    "    tock = time.perf_counter()\n",
    "    print(\"Time elapsed (sec) for augmentation is {0}\".format(tock-tick))\n",
    "    \n",
    "    return output_imgs_flat, output_imgs_2d, output_label_set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img_reshape_2d(train_images.iloc[11])\n",
    "print(img.shape)\n",
    "plot_image_with_label_optional(img).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for adding noise to the image. Note that the keypoints are not altered in such a case\n",
    "\n",
    "def add_noise_to_img(image, noise_type = \"NoiseGaussian\"):\n",
    "    \n",
    "    row, col = image.shape\n",
    "    # channel is always 1 because we are dealing with grey scale images\n",
    "    ch = 1\n",
    "    if noise_type == \"NoiseGaussian\":\n",
    "        mean = 100\n",
    "        var = 100\n",
    "        sigma = var ** 0.5\n",
    "        gauss = np.random.normal(mean, sigma, (row, col, ch))\n",
    "        gauss = gauss.reshape(row, col)\n",
    "        noisy = image + gauss\n",
    "\n",
    "    elif noise_type == \"NoiseSaltPepper\":\n",
    "        s_vs_p = 0.5\n",
    "        amount = 0.04\n",
    "        noisy = np.copy(image)\n",
    "        # Salt mode\n",
    "        num_salt = np.ceil(amount * image.size * s_vs_p)\n",
    "        coords = [np.random.randint(0, i - 1, int(num_salt)) for i in image.shape]\n",
    "        noisy[coords] = 1\n",
    "\n",
    "        # Pepper mode\n",
    "        num_pepper = np.ceil(amount * image.size * (1. - s_vs_p))\n",
    "        coords = [np.random.randint(0, i - 1, int(num_pepper)) for i in image.shape]\n",
    "        noisy[coords] = 0\n",
    "  \n",
    "    elif noise_type == \"NoisePoisson\":\n",
    "        vals = len(np.unique(image))\n",
    "        vals = 2 ** np.ceil(np.log2(vals))\n",
    "        noisy = np.random.poisson(image * vals) / float(vals)\n",
    "    \n",
    "    elif noise_type == \"NoiseSpeckle\":\n",
    "        gauss = np.random.randn(row, col, ch)\n",
    "        gauss = gauss.reshape(row, col)        \n",
    "        noisy = image + image * gauss\n",
    "    \n",
    "    return noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/34372480/rotate-point-about-another-point-in-degrees-python\n",
    "def rotate(origin, points, angle):\n",
    "    if angle == 0:\n",
    "        return points\n",
    "    \n",
    "    angle = math.radians(angle)\n",
    "    result = []\n",
    "    ox, oy = origin\n",
    "    for p in range(0, len(points), 2):\n",
    "        px, py = points[p], points[p+1]\n",
    "\n",
    "        qx = ox + math.cos(angle) * (px - ox) - math.sin(angle) * (py - oy)\n",
    "        qy = oy + math.sin(angle) * (px - ox) + math.cos(angle) * (py - oy)\n",
    "        result.append(qx)\n",
    "        result.append(qy)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train_img_flat, temp_train_img_2d, temp_train_labels = augment_images(train_images, train_labels, [\"90L\", \"90R\", \"180V\", \"NoiseGaussian\", \"NoiseSpeckle\", \"NoisePoisson\", \"NoiseSaltPepper\"])\n",
    "\n",
    "print(temp_train_img_flat.shape)\n",
    "print(temp_train_img_2d.shape)\n",
    "print(temp_train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train_labels_df = pd.DataFrame(temp_train_labels, columns = COLUMNS)\n",
    "\n",
    "# Plot left rotation for single image\n",
    "plot_image_with_label_optional(temp_train_img_flat[155], temp_train_labels_df.iloc[155]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot left rotation for single image with 2d numpy array instead of 1d numpy array\n",
    "plot_image_with_label_optional(temp_train_img_2d[155], temp_train_labels_df.iloc[155]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot right rotation for single image\n",
    "plot_image_with_label_optional(temp_train_img_2d[155+num_train_examples], temp_train_labels_df.iloc[155+num_train_examples]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot upside down image rotation for single image\n",
    "plot_image_with_label_optional(temp_train_img_flat[155+(num_train_examples*2)], temp_train_labels_df.iloc[155+(num_train_examples*2)]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mirror image rotation for single image\n",
    "# plot_image_with_label_optional(temp_train_img_flat[155+(num_train_examples*3)], temp_train_labels_df.iloc[155+(num_train_examples*3)]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will need to append the augmented data to the end of our training sets (both images and labels)\n",
    "print(train_images.shape)\n",
    "print(temp_train_img_flat.shape)\n",
    "print(type(train_images))\n",
    "print(type(temp_train_img_flat))\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(temp_train_labels_df.shape)\n",
    "print(type(train_labels))\n",
    "print(type(temp_train_labels_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train_img_flat = pd.DataFrame(temp_train_img_flat, columns = range(0, IMG_DIM * IMG_DIM))\n",
    "temp_train_img_flat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.append(temp_train_img_flat, ignore_index=True)\n",
    "train_labels = train_labels.append(temp_train_labels_df, ignore_index=True)\n",
    "\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_2d = multiple_img_reshape_2d(train_images)\n",
    "test_images_2d = multiple_img_reshape_2d(test_images)\n",
    "\n",
    "print(train_images_2d.shape)\n",
    "print(test_images_2d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deep learning models are known to work well with normalized data. Thus we normalize the image pixel values with the highest pixel value intensity, ie, 255. We also normalize the labels with the width of the image size.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize train and test data\n",
    "\n",
    "train_images = train_images / PIX_MAX\n",
    "test_images = test_images / PIX_MAX\n",
    "train_images_2d = train_images_2d / PIX_MAX\n",
    "test_images_2d = test_images_2d / PIX_MAX\n",
    "\n",
    "train_labels = train_labels / IMG_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now have more samples than the standard training set, which will aid us in our training of the model\n",
    "num_train_examples = train_images.shape[0]\n",
    "num_train_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras import optimizers\n",
    "from keras.layers import Conv2D,Dropout,Dense,Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, Convolution2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout, Conv2D,MaxPool2D, ZeroPadding2D\n",
    "import tensorflow as tf\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Input dimensions: (None, 96, 96, 1)\n",
    "model.add(Convolution2D(32, (3,3), padding='same', use_bias=False, input_shape=(96,96,1)))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Input dimensions: (None, 96, 96, 32)\n",
    "model.add(Convolution2D(32, (3,3), padding='same', use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Input dimensions: (None, 48, 48, 32)\n",
    "model.add(Convolution2D(64, (3,3), padding='same', use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Input dimensions: (None, 48, 48, 64)\n",
    "model.add(Convolution2D(64, (3,3), padding='same', use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Input dimensions: (None, 24, 24, 64)\n",
    "model.add(Convolution2D(96, (3,3), padding='same', use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Input dimensions: (None, 24, 24, 96)\n",
    "model.add(Convolution2D(96, (3,3), padding='same', use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Input dimensions: (None, 12, 12, 96)\n",
    "model.add(Convolution2D(128, (3,3),padding='same', use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Input dimensions: (None, 12, 12, 128)\n",
    "model.add(Convolution2D(128, (3,3),padding='same', use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Input dimensions: (None, 6, 6, 128)\n",
    "model.add(Convolution2D(256, (3,3),padding='same',use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Input dimensions: (None, 6, 6, 256)\n",
    "model.add(Convolution2D(256, (3,3),padding='same',use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Input dimensions: (None, 3, 3, 256)\n",
    "model.add(Convolution2D(512, (3,3), padding='same', use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Input dimensions: (None, 3, 3, 512)\n",
    "model.add(Convolution2D(512, (3,3), padding='same', use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Input dimensions: (None, 3, 3, 512)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(30))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mse','mae'])\n",
    "\n",
    "history = model.fit(train_images_2d, train_labels, epochs = 50, batch_size = int(num_train_examples/1000),validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for test\n",
    "pred = model.predict(test_images_2d)\n",
    "print(np.min(pred))\n",
    "print(np.max(pred))\n",
    "print(np.min(model.predict(train_images_2d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission to Kaggle for Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look up table\n",
    "print(idlookup.head(2))\n",
    "idlookup = idlookup.drop('Location',axis=1)\n",
    "print(idlookup.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = train_labels.columns\n",
    "predictions = pd.DataFrame(pred, columns = feature_names)\n",
    "predictions = predictions * IMG_DIM\n",
    "\n",
    "predictions.head()\n",
    "predictions.stack().reset_index()\n",
    "predictions = predictions.stack().reset_index()\n",
    "predictions.columns = ['index','FeatureName','Location']\n",
    "\n",
    "imageids = test['ImageId']\n",
    "imageids = imageids.reset_index()\n",
    "\n",
    "predictions = predictions.merge(imageids, left_on='index', right_on='index')\n",
    "predictions = predictions.drop('index',axis=1)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = idlookup.merge(predictions, left_on=['FeatureName','ImageId'], right_on=['FeatureName','ImageId'])\n",
    "submission = submission[['RowId','Location']]\n",
    "submission = submission.set_index('RowId')\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission result\n",
    "    \n",
    "if os.getcwd() == CWD:\n",
    "    os.chdir('/project')\n",
    "    # make submissions directory if it doesnt exist\n",
    "    try:\n",
    "        os.makedirs('submissions')\n",
    "    except OSError as e:\n",
    "        pass\n",
    "    \n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\").replace('/','').replace(':','').replace(' ','')\n",
    "    submission.to_csv('submissions/submission-{0}.csv'.format(dt_string))\n",
    "    os.chdir(CWD)\n",
    "    \n",
    "else:\n",
    "    submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
