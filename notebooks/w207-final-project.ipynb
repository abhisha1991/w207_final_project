{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W207 Final Project\n",
    "\n",
    "## Submission by Sirisha Bhupathi and Abhi Sharma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is for the Kaggle competition listed here: https://www.kaggle.com/c/facial-keypoints-detection\n",
    "\n",
    "## Objective\n",
    "\n",
    "The objective of this project is to predict keypoint positions on face images.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The image sizes are 96 x 96 pixels and the key points are represented as location co-ordinates for each image. \n",
    "Location co-ordinates can have 2 values - one for x and one for y. \n",
    "There are a total of 30 location co-ordinates per image, 15 each for the x and y axis.\n",
    "Out of the 30 co-ordinates in the test dataset for a single image, some co-ordinates are present and others need to be predicted. \n",
    "The number and type of co-ordinates that need to be predicted vary per test example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import keras, tf and image depdencies\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We verify if the GPU is working and available with the following commands\n",
    "# Adapted from here: https://www.tensorflow.org/guide/gpu\n",
    "\n",
    "tf_config = tf.compat.v1.ConfigProto(allow_soft_placement=False)\n",
    "tf_config.gpu_options.allow_growth = True\n",
    "s = tf.compat.v1.Session(config=tf_config)\n",
    "tf.compat.v1.keras.backend.set_session(s)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(gpus))\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Create some tensors\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(c)\n",
    "\n",
    "\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "IMG_DIM = 96\n",
    "PIX_MAX = 255\n",
    "IMAGE = 'Image'\n",
    "columns = ['left_eye_center_x', 'left_eye_center_y', 'right_eye_center_x',\n",
    "       'right_eye_center_y', 'left_eye_inner_corner_x',\n",
    "       'left_eye_inner_corner_y', 'left_eye_outer_corner_x',\n",
    "       'left_eye_outer_corner_y', 'right_eye_inner_corner_x',\n",
    "       'right_eye_inner_corner_y', 'right_eye_outer_corner_x',\n",
    "       'right_eye_outer_corner_y', 'left_eyebrow_inner_end_x',\n",
    "       'left_eyebrow_inner_end_y', 'left_eyebrow_outer_end_x',\n",
    "       'left_eyebrow_outer_end_y', 'right_eyebrow_inner_end_x',\n",
    "       'right_eyebrow_inner_end_y', 'right_eyebrow_outer_end_x',\n",
    "       'right_eyebrow_outer_end_y', 'nose_tip_x', 'nose_tip_y',\n",
    "       'mouth_left_corner_x', 'mouth_left_corner_y', 'mouth_right_corner_x',\n",
    "       'mouth_right_corner_y', 'mouth_center_top_lip_x',\n",
    "       'mouth_center_top_lip_y', 'mouth_center_bottom_lip_x',\n",
    "       'mouth_center_bottom_lip_y']\n",
    "\n",
    "CWD = '/project/notebooks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_prefix = '..'\n",
    "if os.getcwd() == CWD:\n",
    "    folder_prefix = '/project/kaggle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(folder_prefix + '/input/facial-keypoints-detection/training.zip')\n",
    "test = pd.read_csv(folder_prefix + '/input/facial-keypoints-detection/test.zip')\n",
    "idlookup = pd.read_csv(folder_prefix + '/input/facial-keypoints-detection/IdLookupTable.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train shape:',train.shape)\n",
    "print('Test shape:',test.shape)\n",
    "print(test.head())\n",
    "train.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "\n",
    "train.isnull().any().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with mean of the column\n",
    "\n",
    "for col in columns:\n",
    "    mean = np.mean(train[col])\n",
    "    train[col] = train[col].fillna(mean)\n",
    "train.isnull().any().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split image column and label columns\n",
    "\n",
    "train_images = train[[IMAGE]]\n",
    "train_labels = train.drop(IMAGE, axis=1)\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train image pixels from string to 1 pixel per column and convert each pixel from string to float\n",
    "train_images = train_images[IMAGE].str.split(' ', expand=True)\n",
    "train_images = train_images.astype(float)\n",
    "\n",
    "train_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split test image pixels from string to 1 pixel per column and convert each pixel from string to float\n",
    "test_images = test.copy()\n",
    "test_images = test_images.set_index('ImageId')\n",
    "test_images = test_images[IMAGE].str.split(' ', expand=True)\n",
    "test_images = test_images.astype(float)\n",
    "\n",
    "test_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of flat representation, have a dataframe with 2d representation of each row's image as well\n",
    "train_images_2d = train_images.values.reshape(-1, IMG_DIM, IMG_DIM, 1)\n",
    "test_images_2d = test_images.values.reshape(-1, IMG_DIM, IMG_DIM, 1)\n",
    "\n",
    "print(train_images_2d.shape)\n",
    "print(test_images_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot images and keypoints\n",
    "\n",
    "# Can try different images\n",
    "image_no = 60 \n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(np.array(train_images.iloc[image_no]).reshape(IMG_DIM, IMG_DIM),cmap='gray')\n",
    "for i in range(0, 30, 2):\n",
    "    plt.scatter(train_labels.iloc[image_no][i],train_labels.iloc[image_no][i+1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize train and test data\n",
    "\n",
    "train_images = train_images/PIX_MAX\n",
    "train_labels = train_labels/IMG_DIM\n",
    "test_images = test_images/PIX_MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_examples = train_images.shape[0]\n",
    "num_train_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras import optimizers\n",
    "from keras.layers import Conv2D,Dropout,Dense,Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, Convolution2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout, Conv2D,MaxPool2D, ZeroPadding2D\n",
    "import tensorflow as tf\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, (3,3), padding='same', use_bias=False, input_shape=(96,96,1)))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Convolution2D(32, (3,3), padding='same', use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, (3,3), padding='same', use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Convolution2D(64, (3,3), padding='same', use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(96, (3,3), padding='same', use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Convolution2D(96, (3,3), padding='same', use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(128, (3,3),padding='same', use_bias=False))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Convolution2D(128, (3,3),padding='same', use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(256, (3,3),padding='same',use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Convolution2D(256, (3,3),padding='same',use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(512, (3,3), padding='same', use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Convolution2D(512, (3,3), padding='same', use_bias=False))\n",
    "model.add(LeakyReLU(alpha = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(30))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mse','mae'])\n",
    "\n",
    "history = model.fit(train_images_2d, train_labels, epochs = 50,batch_size = int(num_train_examples/100),validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for test\n",
    "pred = model.predict(test_images_2d)\n",
    "print(np.min(pred))\n",
    "print(np.max(pred))\n",
    "print(np.min(model.predict(train_images_2d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look up table\n",
    "print(idlookup.head(2))\n",
    "idlookup = idlookup.drop('Location',axis=1)\n",
    "print(idlookup.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = train_labels.columns\n",
    "predictions = pd.DataFrame(pred, columns = feature_names)\n",
    "predictions = predictions * IMG_DIM\n",
    "\n",
    "predictions.head()\n",
    "predictions.stack().reset_index()\n",
    "predictions = predictions.stack().reset_index()\n",
    "predictions.columns = ['index','FeatureName','Location']\n",
    "\n",
    "imageids = test['ImageId']\n",
    "imageids = imageids.reset_index()\n",
    "\n",
    "predictions = predictions.merge(imageids, left_on='index', right_on='index')\n",
    "predictions = predictions.drop('index',axis=1)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = idlookup.merge(predictions, left_on=['FeatureName','ImageId'], right_on=['FeatureName','ImageId'])\n",
    "submission = submission[['RowId','Location']]\n",
    "submission = submission.set_index('RowId')\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission result\n",
    "    \n",
    "if os.getcwd() == CWD:\n",
    "    os.chdir('/project')\n",
    "    # make submissions directory if it doesnt exist\n",
    "    try:\n",
    "        os.makedirs('submissions')\n",
    "    except OSError as e:\n",
    "        pass\n",
    "    \n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\").replace('/','').replace(':','').replace(' ','')\n",
    "    submission.to_csv('submissions/submission-{0}.csv'.format(dt_string))\n",
    "    os.chdir(CWD)\n",
    "    \n",
    "else:\n",
    "    submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
